{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from mps.state import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME EVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from mps.state import _truncate_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the commonly used operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "σz = np.diag([1.0,-1.0])\n",
    "i2 = np.identity(2)\n",
    "σx = np.array([[0, 1], [1, 0]])\n",
    "σy = -1j * σz @ σx\n",
    "\n",
    "def creation_op(d):\n",
    "    # Returns d dimensional cration operator\n",
    "    return np.diag(np.sqrt(np.arange(1,d)),-1).astype(complex)\n",
    "\n",
    "def annihilation_op(d):\n",
    "    # Returns d dimensional cration operator\n",
    "    return np.diag(np.sqrt(np.arange(1,d)),1).astype(complex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Hamiltonians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the interface we use for nearest neighbor interaction Hamiltonians. It is initially empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "class NNHamiltonian(object):\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        #\n",
    "        # Create a nearest-neighbor interaction Hamiltonian\n",
    "        # of a given size, initially empty.\n",
    "        #\n",
    "        self.size = size\n",
    "        \n",
    "    def dimension(self, ndx, t=0.0):\n",
    "        #\n",
    "        # Return the dimension of the local Hilbert space\n",
    "        #\n",
    "        return 0\n",
    "    \n",
    "    def interaction_term(self, ndx, t=0.0):\n",
    "        #\n",
    "        # Return the interaction between sites (ndx,ndx+1)\n",
    "        #\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we can have different local terms and different interactions on every site\n",
    "$$\n",
    "H = \\sum_i \\left[O_i + \\sum_n L^{(n)}_i \\otimes R^{(n)}_{i+1}\\right]_\\text{site i} \n",
    "=  \\sum_{i=0}^{N-2} h_{i,i+1}. \n",
    "$$\n",
    "where\n",
    "$$\n",
    "h_{i,i+1} = \\sum_n L^{(n)}_i \\otimes R^{(n)}_{i+1} +\n",
    "\\begin{cases}\n",
    "O_i + \\frac{1}{2} O_{i+1}, \\text{ if  } i = 0 \\\\\n",
    "\\frac{1}{2} O_i + O_{i+1}, \\text{ if  } i = N-2 \\\\\n",
    "\\frac{1}{2} O_i + \\frac{1}{2} O_{i+1}, \\text{ else  } \n",
    "\\end{cases}\n",
    "$$\n",
    "and $N>2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below computes the interaction terms $h_{i,i+1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "def _compute_interaction_term(H, ndx, t=0.0):\n",
    "    \"\"\"Computes the interaction term between site ndx and ndx+1, including the local terms \n",
    "    for the two sites\n",
    "    \n",
    "    Arguments:\n",
    "    H = NNHamiltonian\n",
    "    ndx = site index\n",
    "    \"\"\"\n",
    "    if isinstance(H.local_terms[ndx], np.ndarray ):            \n",
    "        if ndx == 0:\n",
    "            H.interactions[ndx] +=  np.kron(H.local_terms[ndx],\n",
    "                                               np.eye(H.dimension(ndx+1)))\n",
    "        else:\n",
    "            H.interactions[ndx] +=  0.5 * np.kron(H.local_terms[ndx],\n",
    "                                                     np.eye(H.dimension(ndx+1)))\n",
    "    if isinstance(H.local_terms[ndx+1], np.ndarray ):            \n",
    "        if ndx == H.size-2:\n",
    "            H.interactions[ndx] +=  np.kron(np.eye(H.dimension(ndx)),\n",
    "                                               H.local_terms[ndx+1])\n",
    "        else:\n",
    "            H.interactions[ndx] +=  0.5 * np.kron(np.eye(H.dimension(ndx)),\n",
    "                                                     H.local_terms[ndx+1])\n",
    "\n",
    "    return H.interactions[ndx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "class ConstantNNHamiltonian(NNHamiltonian):\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        #\n",
    "        # Create a nearest-neighbor interaction Hamiltonian with fixed\n",
    "        # local terms and interactions.\n",
    "        #\n",
    "        #  - local_term: operators acting on each site (can be different for each site)\n",
    "        #  - int_left, int_right: list of L and R operators (can be different for each site)\n",
    "        #\n",
    "        self.size = size\n",
    "        self.local_terms = [0] * size\n",
    "        self.int_left = [[]] * (size-1)\n",
    "        self.int_right = [[]] * (size-1)\n",
    "        self.interactions = [0] * (size-1)\n",
    "\n",
    "    def set_local_term(self, ndx, operator):\n",
    "        #\n",
    "        # Set the local term acting on the given site\n",
    "        #\n",
    "        self.local_terms[ndx] = operator\n",
    "\n",
    "    def add_interaction_term(self, ndx, L, R):\n",
    "        #\n",
    "        # Add an interaction term $L \\otimes R$ acting on sites 'ndx' and 'ndx+1'\n",
    "        #\n",
    "        # Add to int_left, int_right\n",
    "        #\n",
    "        # Update the self.interactions[ndx] term\n",
    "        self.int_left[ndx].append(L)\n",
    "        self.int_right[ndx].append(R)\n",
    "        self.interactions[ndx] += np.kron(L,R)\n",
    "        \n",
    "    def dimension(self, ndx, t=0.0):\n",
    "        #\n",
    "        # Return the dimension of the local Hilbert space\n",
    "        #\n",
    "        if ndx == self.size -1:\n",
    "            return self.int_right[ndx-1][0].shape[0]\n",
    "        else:\n",
    "            return self.int_left[ndx][0].shape[0]\n",
    "    \n",
    "    #def interaction_term(self, ndx, t=0.0):\n",
    "        #\n",
    "        # Return the interaction between sites (ndx,ndx+1) including the corresponding local terms.\n",
    "        #\n",
    "        #return _compute_interaction_term(self, ndx, t=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A particular case would be a translationally invariant, constant Hamiltonian\n",
    "$$H = \\sum_i \\left[O + \\sum_n L^{(n)} \\otimes R^{(n)}\\right]_\\text{site i}$$\n",
    "which has the same local term $O$ on all sites, and the same interaction given by the product of $L^{(n)}$ left and $R^{(n)}$ right operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "class TINNHamiltonian(ConstantNNHamiltonian):\n",
    "    \n",
    "    def __init__(self, size, local_term, intL, intR):\n",
    "        #\n",
    "        # Create a constant nearest-neighbor interaction Hamiltonian with fixed\n",
    "        # local terms and interactions.\n",
    "        #\n",
    "        #  - local_term: operator acting on every site\n",
    "        #  - int_left: list of L (applied to site ndx) operators\n",
    "        #  - int_right: list of R (applied to site ndx + 1) operators\n",
    "        #  - interaction: kronecker product of corresponding L and R pairs\n",
    "        #\n",
    "        self.size = size\n",
    "        self.local_terms = [local_term] * size\n",
    "        self.int_left = [[]] * (size-1)\n",
    "        self.int_right = [[]] * (size-1)\n",
    "        self.intL = intL\n",
    "        self.intR = intR\n",
    "        self.interactions = [0] * (size-1)\n",
    "    \n",
    "    def interaction_term(self, ndx, t=0.0):\n",
    "        #\n",
    "        # Return the interaction between sites (ndx,ndx+1)\n",
    "        #\n",
    "        if isinstance(self.interactions[ndx], np.ndarray):\n",
    "            return self.interactions[ndx]\n",
    "        \n",
    "        else:\n",
    "            for L,R in zip(self.intL, self.intR):\n",
    "                self.add_interaction_term(ndx, L, R)\n",
    "               \n",
    "            return _compute_interaction_term(self, ndx, t=0.0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suzuki-Trotter Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Suzuki-Trotter decomposition, the Hamiltonians of the nearest neighbor couplings can be decomposed into two non-commuting parts, $H_{\\text{odd}} $ and $ H_{\\text{even}} $, so that all additive 2-site operators in each part commute with each other.\n",
    "\n",
    "Let us consider a simple example of tight binding model with on-site potential and decompose the Hamiltonian into 2-site terms, so that $H=\\sum_i h_{i,i+1}$. \n",
    "\\begin{equation}\n",
    "h_{i,i+1} = \\left(\\frac{\\omega}{2}  a_i^\\dagger a_i \\right) + \\left(\\frac{\\omega}{2}  a_{i+1}^\\dagger a_{i+1} \\right) - \\left( t a_{i}^\\dagger a_{i+1} + \\text{h.c.} \\right).\n",
    "\\end{equation}\n",
    "Since $[h_{i,i+1},h_{i+2,i+3}] = 0$, we can group these terms for even and odd $i$, so that $H = H_{\\text{odd}} + H_{\\text{even}} $. \n",
    "\n",
    "Note that the local term $ a_i^\\dagger a_i$ appears only in one the groups for $i=1$ and $i=N$. Therefore we need to add two on-site terms $h_1 = \\left(\\frac{\\omega}{2}  a_1^\\dagger a_1 \\right) $ and $h_N = \\left(\\frac{\\omega}{2}  a_N^\\dagger a_N \\right) $, separately. So that $H_{\\text{even}} \\rightarrow H_{\\text{evem}} + h_1$, and $h_N$ is included similarly depending on whether $N$ is even or odd.\n",
    "\n",
    "And for the first order Suzuki-Trotter decomposition, the evolution operator becomes\n",
    "\\begin{equation}\n",
    "e^{-i \\hat{H} \\Delta t} = e^{-i \\hat{H}_{\\text{odd}} \\Delta t}  e^{-i \\hat{H}_{\\text{even}} \\Delta t} + O(\\Delta t^2).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Trotter_unitaries creates a list of Trotter unitarities depending on evenodd value. \n",
    "\n",
    "If evenodd = 0:\n",
    "$$ U_{\\text{odds}} = [U_{1,2}, U_{3,4}, \\dots ], $$\n",
    "and if evenodd = 1:\n",
    "$$ U_{\\text{evens}} = [U_1, U_{2,3}, U_{4,5}, \\dots ], $$\n",
    "where $U_i = e^{-i h_{i} \\Delta t}$ and $U_{i,i+1} = e^{-i h_{i,i+1} \\Delta t}$. \n",
    "\n",
    "Note that the last element of  $U_{\\text{odds/evens}}$ is $U_N$ if $N$ is odd/even, and $U_{N-1,N}$ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "class Trotter_unitaries(object):\n",
    "    \"\"\"\"Create Trotter unitarities from a nearest-neighbor interaction Hamiltonian.\n",
    "        \n",
    "    Attributes:\n",
    "    H = NNHamiltonian\n",
    "    δt = Time step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, H, δt):\n",
    "        self.H = H\n",
    "        self.δt = δt\n",
    "                \n",
    "    def twosite_unitary(self, start):\n",
    "        \"\"\"Creates twp-site exponentials from interaction H terms\"\"\"\n",
    "        U = scipy.linalg.expm(-1j * self.δt * self.H.interaction_term(start))\n",
    "        U = U.reshape(self.H.dimension(start),self.H.dimension(start+1),\n",
    "                      self.H.dimension(start),self.H.dimension(start+1))\n",
    "        return U\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply each $U_{i,i+1} = e^{-i h_{i,i+1} \\Delta t}$ to two neighbouring tensors, $A_i$ and $A_{i+1}$ simultaneously, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig_pdf/apply_mpo_to2site.svg\" style=\"max-width: 90%; width: 35em\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting tensor $B$ is a two-site tensor. We split this tensor into two one-site tensors using left_orth_2site and right_orth_2site functions, which are defined in [this notebook](File%201c%20-%20Canonical%20form.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "def apply_2siteTrotter(U, ψ, start):\n",
    "    return np.einsum('ijk,klm,prjl -> iprm', ψ[start],\n",
    "                     ψ[start+1], U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/evolution.py\n",
    "\n",
    "def TEBD_sweep(H, ψ, δt, dr, evenodd, tol=0):\n",
    "    #\n",
    "    # Apply a TEBD sweep by evolving with the pairwise Trotter Hamiltonian\n",
    "    # starting from left/rightmost site and moving on the 'direction' (>0 right,\n",
    "    # <0 left) by pairs of sites.\n",
    "    #\n",
    "    # - H: NNHamiltonian\n",
    "    # - ψ: Initial state in CanonicalMPS form (modified destructively)\n",
    "    # - δt: Time step\n",
    "    # - evenodd: 0, 1 depending on Trotter step\n",
    "    # - direction: where to move\n",
    "    #\n",
    "    Trotter = Trotter_unitaries(H, δt)        \n",
    "    def update_two_site(start, nextsite, dr):\n",
    "        # Apply combined local and interaction exponential and move\n",
    "        ψ.center = ψ.center + dr\n",
    "        if start == 0:\n",
    "            dr = +1\n",
    "        elif start == (ψ.size-2):\n",
    "            dr = -1\n",
    "        AA = apply_2siteTrotter(Trotter.twosite_unitary(start) , ψ, start)\n",
    "        ψ.update_canonical_2site(AA, start, nextsite, dr, tolerance=tol)\n",
    "\n",
    "    #\n",
    "    # Loop over ψ, updating pairs of sites acting with the unitary operator\n",
    "    # made of the interaction and 0.5 times the local terms\n",
    "    #\n",
    "    if dr < 0:\n",
    "        for j in range(ψ.size-2, -1, -2):\n",
    "            print(ψ.center)\n",
    "            update_two_site(j, j+1, dr)\n",
    "    else:\n",
    "        for j in range(0, ψ.size-1, +2):\n",
    "            print(ψ.center)\n",
    "            update_two_site(j, j+1, dr)        \n",
    "            \n",
    "    return ψ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error in Suzuki-Trotter decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first order Suzuki-Trotter decomposition, evolution operator becomes\n",
    "\\begin{equation}\n",
    "e^{-i \\hat{H} \\Delta t} = e^{-i \\hat{H}_{\\text{odd}} \\Delta t}  e^{-i \\hat{H}_{\\text{even}} \\Delta t} + O(\\Delta t^2).\n",
    "\\end{equation}\n",
    "Note that after $T/\\Delta t$ time steps, the accumulated error is in the order of $\\Delta t$.\n",
    "Higher order Suzuki-Trotter decompositions can be used to reduce error.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: mps/test/test_TEBD.py\n",
    "import unittest\n",
    "import mps.state\n",
    "import mps.tools\n",
    "from mps.evolution import *\n",
    "from mps.test.tools import *\n",
    "import scipy.sparse as sp\n",
    "\n",
    "N = 7\n",
    "t = 1\n",
    "ω = 0.5\n",
    "        \n",
    "def random_wavefunction(n):\n",
    "    ψ = np.random.rand(n) - 0.5\n",
    "    return ψ / np.linalg.norm(ψ)\n",
    "\n",
    "class TestTEBD_sweep(unittest.TestCase):\n",
    "    \n",
    "    def test_orthonormalization(self):\n",
    "        #\n",
    "        # We verify that our two-site orthonormalization procedure, \n",
    "        # does not change the state\n",
    "        #\n",
    "        δt = 0.1\n",
    "\n",
    "        def ok(Ψ):\n",
    "            H = TINNHamiltonian(Ψ.size, 0*σx, [mps.tools.random_Pauli()], [mps.tools.random_Pauli()])\n",
    "            Trotter = Trotter_unitaries(H, δt)\n",
    "            for start in range(Ψ.size-2):\n",
    "                AA = apply_2siteTrotter(Trotter.twosite_unitary(start) , \n",
    "                                                      Ψ, start)\n",
    "                A, AC = mps.state.left_orth_2site(AA, DEFAULT_TOLERANCE)\n",
    "                AA_orth = np.einsum(\"ijk,klm -> ijlm\", A, AC)\n",
    "                self.assertTrue(similar(AA,AA_orth))    \n",
    "                \n",
    "                AA = apply_2siteTrotter(Trotter.twosite_unitary(start) , \n",
    "                                                      Ψ, start)\n",
    "                A, AC = mps.state.right_orth_2site(AA, DEFAULT_TOLERANCE)\n",
    "                AA_orth = np.einsum(\"ijk,klm -> ijlm\", AC, A)\n",
    "                self.assertTrue(similar(AA,AA_orth))\n",
    "            \n",
    "            \n",
    "        test_over_random_mps(ok)\n",
    "        \n",
    "    def test_right_sweep(self):\n",
    "        #\n",
    "        # We verify the truncation procedure does not change the resulting state. \n",
    "        # We evolve the mps only through one sweep to eliminate the error due to \n",
    "        # non-commuting terms in the Hamiltonian. We compare the TEBD results with \n",
    "        # exact diagonalization results.\n",
    "        #\n",
    "        # Note that there is a phase difference between the two wavefunctions.\n",
    "        # However absolute values of the corresponding coefficients are equal \n",
    "        # as the test verifies.\n",
    "        #                \n",
    "        dt = 1\n",
    "        ψwave = random_wavefunction(N)\n",
    "        ψmps = CanonicalMPS(mps.state.wavepacket(ψwave), center=0)\n",
    "        # We use the tight-binding Hamiltonian\n",
    "                \n",
    "        H=TINNHamiltonian(N, ω*creation_op(2)@ annihilation_op(2), \n",
    "                            [t * annihilation_op(2) , t * creation_op(2)], \n",
    "                            [creation_op(2), annihilation_op(2)])\n",
    "        ψmps_final = TEBD_sweep(H, ψmps, dt, 1, 0, tol=DEFAULT_TOLERANCE)\n",
    "        Hmat = sp.diags([[t,0]*(N//2), ω, [t,0]*(N//2)],\n",
    "                  offsets=[-1,0,+1],\n",
    "                  shape=(N,N),\n",
    "                  dtype=np.complex128)\n",
    "        ψwave_final = sp.linalg.expm_multiply(-1j * dt * Hmat, ψwave)\n",
    "        print(abs(mps.state.wavepacket(ψwave_final).tovector()))\n",
    "        print(abs(ψmps_final.tovector()))\n",
    "        print(np.vdot(abs(mps.state.wavepacket(ψwave_final).tovector()), abs(ψmps_final.tovector())))\n",
    "        self.assertTrue(similar(abs(mps.state.wavepacket(ψwave_final).tovector()), \n",
    "                                abs(ψmps_final.tovector())))\n",
    "     \n",
    "    \n",
    "    def test_left_sweep(self):\n",
    "        #\n",
    "        # We verify the truncation procedure does not change the resulting state. \n",
    "        # We evolve the mps only through one sweep to eliminate the error due to \n",
    "        # non-commuting terms in the Hamiltonian. We compare the TEBD results with \n",
    "        # exact diagonalization results.\n",
    "        #\n",
    "        # Note that there is a phase difference between the two wavefunctions.\n",
    "        # However absolute values of the corresponding coefficients are equal \n",
    "        # as the test verifies.\n",
    "        #                \n",
    "        dt = 1\n",
    "        ψwave = random_wavefunction(N)\n",
    "        ψmps = CanonicalMPS(mps.state.wavepacket(ψwave), center=N-1)\n",
    "        # We use the tight-binding Hamiltonian\n",
    "                \n",
    "        H=TINNHamiltonian(N, ω*creation_op(2)@ annihilation_op(2), \n",
    "                            [t * annihilation_op(2) , t * creation_op(2)], \n",
    "                            [creation_op(2), annihilation_op(2)])\n",
    "        \n",
    "  \n",
    "        ψmps_final = TEBD_sweep(H, ψmps, dt, -1, 0, tol=DEFAULT_TOLERANCE)\n",
    "        Hmat = sp.diags([[0,t]*(N//2), ω, [0,t]*(N//2)],\n",
    "                  offsets=[-1,0,+1],\n",
    "                  shape=(N,N),\n",
    "                  dtype=np.complex128)\n",
    "        ψwave_final = sp.linalg.expm_multiply(-1j * dt * Hmat, ψwave)\n",
    "        print(abs(mps.state.wavepacket(ψwave_final).tovector()))\n",
    "        print(abs(ψmps_final.tovector()))\n",
    "        print(np.vdot(abs(mps.state.wavepacket(ψwave_final).tovector()), abs(ψmps_final.tovector())))\n",
    "        \n",
    "        self.assertTrue(similar(abs(mps.state.wavepacket(ψwave_final).tovector()), \n",
    "                                abs(ψmps_final.tovector())))\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_left_sweep (__main__.TestTEBD_sweep) ... FAIL\n",
      "test_orthonormalization (__main__.TestTEBD_sweep) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "2\n",
      "[ 0.          0.22619679  0.34182869  0.          0.46041405  0.          0.\n",
      "  0.          0.44526872  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.31322022  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.4104937   0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.39386653  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "[  1.17572733e-017   2.38447873e-001   3.33398337e-001   1.30760700e-017\n",
      "   4.60414055e-001   3.32944568e-017   5.82397354e-018   2.00195580e-034\n",
      "   4.45268718e-001   3.51272144e-017   3.09795840e-017   8.76631067e-034\n",
      "   3.61446318e-017   2.61376877e-033   4.57208847e-034   1.57162785e-050\n",
      "   3.13220215e-001   2.25918978e-017   4.40807816e-018   3.89120184e-034\n",
      "   1.00086803e-017   7.23769334e-034   1.26604062e-034   4.35193831e-051\n",
      "   5.19309235e-017   3.87307724e-033   1.60332992e-033   3.25225598e-050\n",
      "   1.46316666e-033   1.05807672e-049   1.85082185e-050   6.36208855e-067\n",
      "   4.10493703e-001   2.96080245e-017   5.77704834e-018   5.09965121e-034\n",
      "   1.31169702e-017   9.48542717e-034   1.65922145e-034   5.70347373e-051\n",
      "   6.80585608e-017   5.07589785e-033   2.10125913e-033   4.26227470e-050\n",
      "   1.91756685e-033   1.38667241e-049   2.42561200e-050   8.33789507e-067\n",
      "   1.01321371e-016   1.11216289e-018   1.55502859e-018   6.09890945e-035\n",
      "   2.14745228e-018   1.55291213e-034   2.71640388e-035   9.33747463e-052\n",
      "   2.07681176e-018   1.63839518e-034   1.44494239e-034   4.08876177e-051\n",
      "   1.68584932e-034   1.21910781e-050   2.13250263e-051   7.33034925e-068\n",
      "   3.93866532e-001   2.84087425e-017   5.54304727e-018   4.89308831e-034\n",
      "   1.25856634e-017   9.10121710e-034   1.59201419e-034   5.47245282e-051\n",
      "   6.53018284e-017   4.87029708e-033   2.01614700e-033   4.08962999e-050\n",
      "   1.83989523e-033   1.33050482e-049   2.32736186e-050   8.00016613e-067\n",
      "   9.72173187e-017   1.06711440e-018   1.49204169e-018   5.85187129e-035\n",
      "   2.06046908e-018   1.49001096e-034   2.60637513e-035   8.95925742e-052\n",
      "   1.99268988e-018   1.57203149e-034   1.38641456e-034   3.92314525e-051\n",
      "   1.61756348e-034   1.16972749e-050   2.04612497e-051   7.03343125e-068\n",
      "   9.62964972e-034   7.27600236e-050   9.64597241e-051   1.16280541e-066\n",
      "   2.73052375e-050   1.97455538e-066   3.45395583e-067   1.18727650e-083\n",
      "   1.60578895e-049   1.21887248e-065   5.05258619e-066   1.11046627e-082\n",
      "   4.70940475e-066   3.40556660e-082   5.95712671e-083   2.04772640e-099\n",
      "   2.42635388e-049   2.60898987e-051   3.64789534e-051   1.43072503e-067\n",
      "   5.03764445e-051   3.64293040e-067   6.37233110e-068   2.19045041e-084\n",
      "   4.87193096e-051   3.84346253e-067   3.38964738e-067   9.59170466e-084\n",
      "   3.95478378e-067   2.85986877e-083   5.00257450e-084   1.71960483e-100]\n",
      "0.999889420036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_right_sweep (__main__.TestTEBD_sweep) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "[ 0.          0.37539447  0.49063062  0.          0.38468262  0.          0.\n",
      "  0.          0.4239889   0.          0.          0.          0.          0.\n",
      "  0.          0.          0.30555248  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.2929899   0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.33377819  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "[  2.00692735e-17   3.75394468e-01   4.90630623e-01   3.71841805e-17\n",
      "   3.84682616e-01   3.19094500e-17   3.85167721e-17   2.91913007e-33\n",
      "   4.23988904e-01   8.99854284e-17   1.08615419e-16   8.23180448e-33\n",
      "   5.98017936e-17   3.15449224e-33   3.57794197e-33   2.71167012e-49\n",
      "   3.05552479e-01   7.30541893e-17   9.95313106e-17   7.54333310e-33\n",
      "   3.10143751e-17   3.22834888e-33   4.40709913e-33   3.34007625e-49\n",
      "   4.63452826e-17   9.83610674e-33   1.18725096e-32   8.99800212e-49\n",
      "   6.53680086e-33   3.44810520e-49   3.91096867e-49   2.96406620e-65\n",
      "   3.20286524e-01   1.09255834e-16   1.34597938e-16   1.02009817e-32\n",
      "   8.61816409e-17   5.73112859e-33   6.94234314e-33   5.26150078e-49\n",
      "   6.15489078e-17   1.30628533e-32   1.57673005e-32   1.19498074e-48\n",
      "   8.68120616e-33   4.57926022e-49   5.19396659e-49   3.93643165e-65\n",
      "   6.55508976e-17   1.15998656e-32   1.49247463e-32   1.13112479e-48\n",
      "   3.15470801e-33   5.60901839e-50   1.94900599e-49   1.47712326e-65\n",
      "   5.21917113e-33   1.10769255e-48   1.33702193e-48   1.01330945e-64\n",
      "   7.36141422e-49   3.88308153e-65   4.40433494e-65   3.33798131e-81\n",
      "   3.07680850e-01   1.76814480e-16   2.21659342e-16   1.67992388e-32\n",
      "   1.60416143e-16   1.19447976e-32   1.44274974e-32   1.09343902e-48\n",
      "   1.42868254e-16   3.03216923e-32   3.65992960e-32   2.77380735e-48\n",
      "   2.01509469e-32   1.06294480e-48   1.20563137e-48   9.13730460e-65\n",
      "   1.23990655e-16   2.44609166e-32   3.28313656e-32   2.48824139e-48\n",
      "   6.05026551e-33   7.03345028e-49   1.05008333e-48   7.95842867e-65\n",
      "   1.33018412e-32   2.82312077e-48   3.40760112e-48   2.58257127e-64\n",
      "   1.87616694e-48   9.89661627e-65   1.12251088e-64   8.50734653e-81\n",
      "   4.92927830e-17   2.35977650e-32   2.95676240e-32   2.24088717e-48\n",
      "   1.97857054e-32   1.42643242e-48   1.74075350e-48   1.31929173e-64\n",
      "   1.59644663e-32   3.38822391e-48   4.08969949e-48   3.09952369e-64\n",
      "   2.25171864e-48   1.18776186e-64   1.34720351e-64   1.02102592e-80\n",
      "   1.49143795e-32   2.66002970e-48   3.55860745e-48   2.69701676e-64\n",
      "   4.27843225e-49   6.51243846e-65   9.88049491e-65   7.48828321e-81\n",
      "   1.60954692e-48   3.41602735e-64   4.12325917e-64   3.12495808e-80\n",
      "   2.27019603e-64   1.19750852e-80   1.35825853e-80   1.02940436e-96]\n",
      "0.999286911688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_left_sweep (__main__.TestTEBD_sweep)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-25-d663c40736c6>\", line 109, in test_left_sweep\n",
      "    abs(ψmps_final.tovector())))\n",
      "AssertionError: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_right_sweep (__main__.TestTEBD_sweep)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-25-d663c40736c6>\", line 74, in test_right_sweep\n",
      "    abs(ψmps_final.tovector())))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.905s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "suite1 = unittest.TestLoader().loadTestsFromNames(['__main__.TestTEBD_sweep'])\n",
    "unittest.TextTestRunner(verbosity=2).run(suite1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 4\n",
    "t = 1\n",
    "ω = 0\n",
    "H=TINNHamiltonian(N, ω*creation_op(2)@ annihilation_op(2), \n",
    "                            [t * annihilation_op(2) , t * creation_op(2)], \n",
    "                            [creation_op(2), annihilation_op(2)])\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "       [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
       "       [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
       "       [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.interaction_term(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "δt=1\n",
    "Trotter = Trotter_unitaries(H, δt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000+0.j        ,  0.00000000-0.84147098j],\n",
       "        [ 0.54030231+0.j        ,  0.00000000+0.j        ]],\n",
       "\n",
       "       [[ 0.00000000+0.j        ,  0.00000000+0.j        ],\n",
       "        [ 0.00000000+0.j        ,  1.00000000+0.j        ]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trotter.twosite_unitary(2)[1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hmat = sp.diags([[0,t]*(N//2), ω, [0,t]*(N//2)],\n",
    "                  offsets=[-1,0,+1],\n",
    "                  shape=(N,N),\n",
    "                  dtype=np.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hmat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "Hmat = sp.diags([[0,t]*(N//2), ω, [0,t]*(N//2)],\n",
    "                  offsets=[-1,0,+1],\n",
    "                  shape=(N,N),\n",
    "                  dtype=np.complex128)\n",
    "\n",
    "Hmat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
